{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"dataset/\"\n",
    "img_width, img_height = 224,224\n",
    "classes = [\"manipuri\", \"bharatanatyam\", \"odissi\", \"kathakali\", \"kathak\", \"sattriya\", \"kuchipudi\", \"mohiniyattam\"]\n",
    "class_names_label = {classes:i for i, classes in enumerate(set(classes))}\n",
    "num_classes = len(classes)\n",
    "# resnet_weights_path = 'resnet_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# resnet_weights_path = ('https://github.com/fchollet/deep-learning-models/'\n",
    "#                        'releases/download/v0.2/'\n",
    "#                        'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_width, img_height),cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "def norm_images(images):\n",
    "    images = np.array(images,dtype = 'float32') / 255.  \n",
    "    mean_img = np.mean(images,axos = 0)\n",
    "    std_img = np.std(images,axis = 0)\n",
    "    norm_img = (images - mean_img)/std_img\n",
    "    return norm_img\n",
    "\n",
    "def load_dataset(folder_name):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_file = pd.read_csv(os.path.join(datapath,folder_name+\".csv\"))\n",
    "    for file in tqdm(os.listdir(os.path.join(datapath,folder_name))):\n",
    "        if(folder_name == \"train\"):\n",
    "            label = class_names_label[label_file[label_file[\"Image\"] == file][\"target\"].values[0]]\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            labels.append(file)\n",
    "        image = load_images(os.path.join(datapath,folder_name,file))\n",
    "        images.append(image)\n",
    "    norm_img = np.array(images,dtype = 'float32') / 255.  \n",
    "    return (norm_img,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:01<00:00, 214.21it/s]\n",
      "100%|██████████| 156/156 [00:00<00:00, 231.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train)=load_dataset(\"train\")\n",
    "x_train,y_train = shuffle(x_train,y_train,random_state = 42)\n",
    "(x_test, img_name) = load_dataset(\"test\")\n",
    "y_train = np.array(y_train, dtype = 'int16')\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sol(name):\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = np.argmax(predictions,axis = 1)\n",
    "    y_maps = dict()\n",
    "    y_maps = {v:k for k,v in class_names_label.items()}\n",
    "    print(y_maps)\n",
    "    print(predictions)\n",
    "    pred_labels = [y_maps[k] for k in predictions]\n",
    "    print(pred_labels)\n",
    "    sub = pd.DataFrame({'Image':img_name,'target':pred_labels})\n",
    "    model.save('resnet_weights/'+name+'weights.h5')\n",
    "    sub.to_csv(name+'sol.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 54, 54, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 52, 52, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               11075712  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 11,397,800\n",
      "Trainable params: 11,397,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3,3), activation='relu', padding='same',input_shape = (img_width, img_height,3)))\n",
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 254 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "254/254 [==============================] - 23s 89ms/step - loss: 2.1289 - accuracy: 0.1260 - val_loss: 2.0737 - val_accuracy: 0.1636\n",
      "Epoch 2/10\n",
      "254/254 [==============================] - 19s 76ms/step - loss: 2.0751 - accuracy: 0.1772 - val_loss: 2.0751 - val_accuracy: 0.2091\n",
      "Epoch 3/10\n",
      "254/254 [==============================] - 27s 106ms/step - loss: 2.0715 - accuracy: 0.1811 - val_loss: 2.0602 - val_accuracy: 0.1545\n",
      "Epoch 4/10\n",
      "254/254 [==============================] - 27s 106ms/step - loss: 2.0562 - accuracy: 0.1929 - val_loss: 2.0634 - val_accuracy: 0.1727\n",
      "Epoch 5/10\n",
      "254/254 [==============================] - 28s 110ms/step - loss: 2.0472 - accuracy: 0.1811 - val_loss: 2.0247 - val_accuracy: 0.1364\n",
      "{0: 'mohiniyattam', 1: 'bharatanatyam', 2: 'odissi', 3: 'sattriya', 4: 'kathakali', 5: 'kuchipudi', 6: 'manipuri', 7: 'kathak'}\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 2 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4]\n",
      "['kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'odissi', 'kathakali', 'odissi', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali', 'kathakali']\n"
     ]
    }
   ],
   "source": [
    "early_stops = EarlyStopping(patience=3, monitor='val_accuracy')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=10, validation_split=0.3, callbacks=[early_stops])\n",
    "generate_sol(\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning With ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 23,885,064\n",
      "Trainable params: 23,831,944\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet',input_tensor=Input(shape=(img_width,img_height,3))))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 254 samples, validate on 110 samples\n",
      "Epoch 1/15\n",
      "254/254 [==============================] - 144s 567ms/step - loss: 1.9259 - accuracy: 0.2874 - val_loss: 2.2863 - val_accuracy: 0.1000\n",
      "Epoch 2/15\n",
      "200/254 [======================>.......] - ETA: 21s - loss: 0.9830 - accuracy: 0.7000 "
     ]
    }
   ],
   "source": [
    "early_stops = EarlyStopping(patience=3, monitor='val_accuracy')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=15, validation_split=0.3, callbacks=[early_stops])\n",
    "generate_sol(\"pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 without data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False, weights='imagenet', \n",
    "                                     input_shape=(img_width, img_height,3))\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = Flatten()(output)\n",
    "\n",
    "resnet = Model(resnet.input, output)\n",
    "resnet.trainable = False\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in resnet.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable layers:\", resnet.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(512, activation='relu', input_dim=(img_width, img_height,3)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stops = EarlyStopping(patience=3, monitor='val_accuracy')\n",
    "\n",
    "history1 = model.fit(x_train, y_train, batch_size=100, epochs=15, validation_split=0.3, callbacks=[early_stops])\n",
    "generate_sol(\"withoutdataaug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet with Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range = 40, width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.3)\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train,shuffle = True,subset=\"training\",batch_size=32)\n",
    "val_generator = datagen.flow(x_train, y_train,shuffle = True,subset = \"validation\", batch_size=32)\n",
    "#val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(512, activation='relu', input_dim=(img_width, img_height,3)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=15,\n",
    "                          validation_data=val_generator, validation_steps=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet_weights/tlearn_transfer_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "# t = f.suptitle('Pre-trained CNN (Transfer Learning) Performance', fontsize=12)\n",
    "# f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "# epoch_list = list(range(1,11))\n",
    "# ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "# ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# ax1.set_xticks(np.arange(0, 31, 5))\n",
    "# ax1.set_ylabel('Accuracy Value')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.set_title('Accuracy')\n",
    "# l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "# ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "# ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "# # ax2.set_xticks(np.arange(0, 31, 5))\n",
    "# ax2.set_ylabel('Loss Value')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.set_title('Loss')\n",
    "# l2 = ax2.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
